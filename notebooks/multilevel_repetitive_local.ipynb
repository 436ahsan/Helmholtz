{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "failing-perfume",
   "metadata": {},
   "source": [
    "# 1D Helmholtz Multilevel Development: Repetitive; Local Coarsening Derivation\n",
    "* Constant $k$.\n",
    "* Discretization: 5-point (4th order).\n",
    "* Kaczmarz relaxation.\n",
    "* Fixed-domain problem; repetitive, so we sample windows from a test vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fatal-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%run /Users/olivne/helmholtz/src/helmholtz/startup.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca363760-f09e-4ea3-9c3e-81aadf98c2ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3k/z6rf4cwj2b1bs57qshd9j_k4fbwv1r/T/ipykernel_30257/4043161476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fixed seed for reproducible results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Domain size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Fixed seed for reproducible results.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Domain size.\n",
    "n = 96\n",
    "# Scaled wave number. Fit so lam_min = 0 (integer # periods in domain).\n",
    "kh = helmholtz.analysis.ideal.find_singular_kh(\"5-point\", n)[0]\n",
    "\n",
    "repetitive = True\n",
    "\n",
    "# Number of test vectors.\n",
    "num_examples = 3\n",
    "threshold = 0.1\n",
    "\n",
    "# Boottstrapping parameters.\n",
    "interpolation_method = \"ls\"\n",
    "neighborhood = \"extended\" #\"aggregate\" # \"extended\"\n",
    "num_test_examples = 5\n",
    "leeway_factor = 1.3\n",
    "\n",
    "_LOGGER.info(\"kh {}\".format(kh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e51279-8734-442c-88db-462f5b1edaab",
   "metadata": {},
   "source": [
    "## Level 0->1 Coarsening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd63abe-591b-4579-a358-d0e9ae6863f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine-level matrix.\n",
    "a = hm.linalg.helmholtz_1d_discrete_operator(kh, \"5-point\", n) #, bc=\"bloch\")\n",
    "# Use default Kacmzarz for kh != 0.\n",
    "level = hm.setup.hierarchy.create_finest_level(a, relaxer=hm.solve.relax.GsRelaxer(a) if kh == 0 else None)\n",
    "\n",
    "# Initialize hierarchy to 1-level.\n",
    "finest = 0\n",
    "multilevel = hm.setup.hierarchy.multilevel.Multilevel.create(level)\n",
    "\n",
    "# TV and TV residual history.\n",
    "x_log = []\n",
    "r_log = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a77b33-41f8-4b8e-b930-b1111f783374",
   "metadata": {},
   "source": [
    "### Relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b90d7d-a93c-4c7e-bacd-19b5f15e878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_info = hm.solve.smoothing.check_relax_cycle_shrinkage(\n",
    "    multilevel, num_levels=1, leeway_factor=leeway_factor, slow_conv_factor=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e12237-be4d-4d20-bcc6-2884284c6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate relaxed vectors.\n",
    "level = multilevel[0]\n",
    "_LOGGER.info(\"Generating {} TVs with {} sweeps\".format(x.shape[1], num_sweeps))\n",
    "x = hm.setup.auto_setup.get_test_matrix(a, num_sweeps, num_examples=num_examples)\n",
    "_LOGGER.info(\"RER {:.3f}\".format(norm(level.a.dot(x)) / norm(x)))\n",
    "x_log.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8ea80-45ed-47b0-aa8e-85fcdc5526e6",
   "metadata": {},
   "source": [
    "### Coarsening: Fixed (4/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02954b00-7662-4253-aa30-e8b770283a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coarsening. Force 2 coarse vars per aggregate so we can test alignment.\n",
    "aggregate_size = 4\n",
    "num_components = 2\n",
    "\n",
    "# Optimize aggregate_size, num_components using mock cycle rates.\n",
    "# coarsener = hm.setup.coarsening_uniform.UniformCoarsener(\n",
    "#     level, x, num_sweeps, repetitive=repetitive)\n",
    "# info = coarsener.get_coarsening_info(1, fmt=\"dataframe\")\n",
    "# r, aggregate_size, nc, cr, mean_energy_error, mock_conv, mock_work, mock_efficiency = \\\n",
    "#     coarsener.get_optimal_coarsening(1)\n",
    "# _LOGGER.info(\"R {} a {} nc {} cr {:.2f} mean_energy_error {:.4f}; mock cycle num_sweeps {} conv {:.2f} \"\n",
    "#              \"eff {:.2f}\".format(\n",
    "#     r.shape, aggregate_size, nc, cr, mean_energy_error, num_sweeps, mock_conv, mock_efficiency))\n",
    "# coarsener.get_coarsening_info(1, fmt=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ddc89-30cc-4203-b927-0b9f3a363d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = create_coarsening(x, aggregate_size, num_components)\n",
    "R = r.tile(level.size // aggregate_size)\n",
    "xc = R.dot(x)\n",
    "display(pd.DataFrame(R[:5,:10].todense()))\n",
    "hm.repetitive.locality.plot_coarsening(R, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a24f433-0128-4164-bc0d-22befa14b4c9",
   "metadata": {},
   "source": [
    "### Local Mock Cycle (LMC) Rate\n",
    "The mock cycle rate is calculated on a domain of size $4 a$, $a$ = aggregate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f458cd4-936d-41f8-9015-0c6423f0cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate local mock cycle convergence rate on a domain of size 4 * aggregate_size.\n",
    "m = 4\n",
    "nu_values = np.arange(1, num_sweeps + 1)\n",
    "mock_conv = hm.repetitive.locality.mock_conv_factor_for_domain_size(kh, r, aggregate_size, m * aggregate_size, nu_values)\n",
    "_LOGGER.info(\"Mock cycle conv |domain|={} {}\".format(\n",
    "    m * aggregate_size, np.array2string(mock_conv, precision=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af03334-0972-4471-be8f-15782dc41f93",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "Using $P = R^T$ to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16573fe-6e58-4419-a9e1-e9c0f4ecd274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caliber = 2\n",
    "# interpolation_method = \"svd\"\n",
    "# neighborhood = \"extended\"\n",
    "\n",
    "# p = create_interpolation(\n",
    "#     x_level, level.a, r, interpolation_method, aggregate_size=aggregate_size, nc=num_components, \n",
    "#     neighborhood=neighborhood, repetitive=repetitive, target_error=target_error,\n",
    "#     caliber=caliber)\n",
    "\n",
    "# for title, x_set in (((\"all\", x),) if repetitive else ((\"fit\", x_fit), (\"test\", x_test))):\n",
    "#     error = norm(x_set - p.dot(r.dot(x_set)), axis=0) / norm(x_set, axis=0)\n",
    "#     error_a = norm(level.a.dot(x_set - p.dot(r.dot(x_set))), axis=0) / norm(x_set, axis=0)\n",
    "#     _LOGGER.info(\n",
    "#         \"{:<4s} set size {:<2d} P L2 error mean {:.2f} max {:.2f} A error mean {:.2f} max {:.2f}\".format(\n",
    "#             title, len(error), np.mean(error), np.max(error), np.mean(error_a), np.max(error_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffcc42-2808-4586-bf22-afcd11e76ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess for interpoation: P = R^T on a single aggregate.\n",
    "p = r.tile(1).transpose()\n",
    "print(p.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a4ae7-4f64-4e2e-b386-319a91864487",
   "metadata": {},
   "source": [
    "### Local Two-level Cycle (L2C) Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790053da-a105-49b5-b07b-b7015d5d7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu = 2\n",
    "# local_multilevel = hm.repetitive.locality.create_two_level_hierarchy(kh, m * aggregate_size, r.asarray(), p, aggregate_size)\n",
    "# y, _ = hm.repetitive.locality.two_level_conv_factor(local_multilevel, nu, print_frequency=1)\n",
    "\n",
    "# # Asymptotic vector.\n",
    "# plt.title(\"Asymptotically Slowest Vector in Two-level Cycle({},0)\".format(nu))\n",
    "# e = y - local_multilevel[1].p.dot(local_multilevel[1].r.dot(y))\n",
    "# plt.plot(y, label=\"x\");\n",
    "# plt.plot(e, label=\"x - PRx\");\n",
    "# plt.grid(True);\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6766d744-e8a2-4051-890f-34a32039453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_level_conv = np.array([\n",
    "    two_level_conv_factor(hm.repetitive.locality.create_two_level_hierarchy(\n",
    "        kh, m * aggregate_size, r.asarray(), p, aggregate_size), nu)[1]\n",
    "     for nu in nu_values])\n",
    "\n",
    "conv = pd.DataFrame(np.array((mock_conv, two_level_conv)).transpose(), \n",
    "                    index=nu_values, columns=(\"Mock\", \"Two-level\")).transpose()\n",
    "display(conv)\n",
    "\n",
    "# Compare the L2 projection norm and the A*A'-orthogonal projection norms, which gives an indication\n",
    "# that the mock cycle rates are guaranteed to be good predictors of the two-level rates [Rob & James].\n",
    "R = r.tile(n // aggregate_size)\n",
    "_LOGGER.info(\"L2 projection norm {:.2f} A*A' projection norm {:.2f}\".\n",
    "             format(norm(R.todense(), ord=2), norm((R.dot(multilevel[0].a)).todense(), ord=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb49c06-224c-4ff4-87a8-1649e650bbc0",
   "metadata": {},
   "source": [
    "This intepolation is good up to $\\nu = 2$, conv $\\approx 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065cab5-5772-4cb6-9a38-e623ecfce1e0",
   "metadata": {},
   "source": [
    "<!-- ### Build Coarse Level: Two-level Bootstrap Cycle -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5163b8-56d3-4349-8f04-7fba7292a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_levels = 2\n",
    "# num_bootstrap_steps = 1\n",
    "\n",
    "# # Bootstrap with an increasingly deeper hierarchy (add one level at a time).\n",
    "# num_levels = 2\n",
    "# _LOGGER.info(\"bootstrap on grid size {} with {} levels\".format(x.shape[0], max_levels))\n",
    "# _LOGGER.info(\"-\" * 80)\n",
    "# for i in range(num_bootstrap_steps):\n",
    "#     _LOGGER.info(\"Bootstrap step {}/{}\".format(i + 1, num_bootstrap_steps))\n",
    "#     # Set relax_conv_factor to a high value so that we never append a bootstrap vector to the TV set.\n",
    "#     x, multilevel = hm.setup.auto_setup.bootstap(\n",
    "#         x, multilevel, num_levels, 2.0,\n",
    "#         num_sweeps=num_sweeps, interpolation_method=interpolation_method, \n",
    "#         neighborhood=neighborhood, repetitive=repetitive, target_error=0.1)\n",
    "#     x_log.append(x)\n",
    "#     r_log.append(multilevel[1].r)\n",
    "#     _LOGGER.info(\"RER {:.6f}\".format(norm(a.dot(x)) / norm(x)))\n",
    "#     _LOGGER.info(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2e3c3-6005-4824-824a-a956471763b5",
   "metadata": {},
   "source": [
    "### Two-level Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8ddb1-9564-4036-88c0-cb61850c06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilevel = hm.hierarchy.multilevel.Multilevel.create(level)\n",
    "l = 1\n",
    "r_csr = r.tile(n // aggregate_size)\n",
    "p_csr = r_csr.transpose()\n",
    "level1 = hm.setup.hierarchy.create_coarse_level(level.a, level.b, r_csr, p_csr)\n",
    "_LOGGER.info(\"Level {} size {}\".format(l, level1.size))\n",
    "multilevel.add(level1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa8488-5ed8-4e19-bfb0-1286ee9e719a",
   "metadata": {},
   "source": [
    "#### Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df8cdb-26a7-40b0-a8ff-61861e8d6160",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 8\n",
    "display(pd.DataFrame(multilevel[0].a.todense()[:sz,:sz]))\n",
    "display(pd.DataFrame(multilevel[1].r[:sz,:sz].todense()))\n",
    "display(pd.DataFrame(multilevel[1].p[:sz,:sz].todense()))\n",
    "display(pd.DataFrame(multilevel[1].a[:sz,:sz].todense()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dab42e-75e8-4e9d-8931-d2746b4ed469",
   "metadata": {},
   "source": [
    "#### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50290f6a-0e71-4b55-87e9-f3669dd23036",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(multilevel[1].a[:10,:10].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f089bf1-8bb2-49db-ba0f-fca2768b1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(multilevel[1].p[:10, :10].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a16e7-d02b-405c-bbbc-01aab1543f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(multilevel[1].r[:10,:10].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5a3b1-645c-4f42-a353-9c4628fbd4a8",
   "metadata": {},
   "source": [
    "### Coarse-level Relaxation Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94702d3-7ca3-4e38-b12b-72cec80a20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "work = 1\n",
    "l = 1\n",
    "level = multilevel[l]\n",
    "_LOGGER.info(\"Relax at level {} size {}\".format(l, level.size))\n",
    "b = np.zeros((level.size, num_examples))\n",
    "\n",
    "factor, num_coarse_sweeps, residual, conv, rer, relax_conv_factor = \\\n",
    "    hm.solve.smoothing.shrinkage_factor(\n",
    "        level.operator, lambda x, b: level.relax(x, b), (level.size, ), \n",
    "        print_frequency=1, max_sweeps=20, slow_conv_factor=0.95, leeway_factor=leeway_factor)\n",
    "_LOGGER.info(\"Relax conv {:.2f} shrinkage {:.2f} PODR RER {:.2f} after {} sweeps. Work {:.1f} eff {:.2f}\".format(\n",
    "    relax_conv_factor, factor, np.mean(rer[num_coarse_sweeps]), num_coarse_sweeps, work, np.mean(residual[num_coarse_sweeps] / residual[0]) ** (1/(num_coarse_sweeps * work))))\n",
    "\n",
    "title = \"Relax\"\n",
    "color = \"blue\"\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "hm.solve.smoothing.plot_diminishing_returns_point(factor, num_sweeps, conv, ax, title=title, color=color)\n",
    "print(\"{:<5s} conv {:.2f} shrinkage {:.2f} PODR RER {:.2f} after {:>2d} sweeps. Work {:>2d} efficiency {:.2f}\".format(\n",
    "    title, conv_factor, factor, np.mean(rer[num_coarse_sweeps]), num_coarse_sweeps, work, np.mean(residual[num_coarse_sweeps] / residual[0]) ** (1/(num_coarse_sweeps * work))))\n",
    "ax.set_title(r\"$kh = {:.2f}$\".format(kh))\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b691f-a4ab-4a75-873f-dafe312590fc",
   "metadata": {},
   "source": [
    "### Relaxation Cycle Shrinkage\n",
    "We compare relaxation cycle with $\\nu_1=2, \\nu_2=2, \\nu_{coarse}=20$ with the resulting $P$ and $R$ from the bootstrap step, with Kaczmarz relaxation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c28e4-2ec2-4488-9189-ba87a3dd46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_conv_factor = 0.9\n",
    "nu_pre, nu_post, nu_coarsest = num_sweeps, 0, max(3, num_coarse_sweeps)\n",
    "method_info = hm.solve.smoothing.check_relax_cycle_shrinkage(\n",
    "    multilevel, nu_pre=nu_pre, nu_post=nu_post, nu_coarsest=nu_coarsest, leeway_factor=leeway_factor, slow_conv_factor=slow_conv_factor)\n",
    "num_mini_cycles = method_info[\"Mini-cycle\"][2].shape[0]\n",
    "_LOGGER.info(\"Two-level ({}, {}; {}) relaxation cycle is slow after {} steps\".format(\n",
    "    nu_pre, nu_post, nu_coarsest, num_mini_cycles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2180f0f-21e7-4ca2-b800-feb6ba16a123",
   "metadata": {},
   "source": [
    "### Improve Test Vectors by Relaxation Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeae0c6-932f-40ce-9308-ad2ceb707f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relax_cycle(x):\n",
    "    return hm.solve.relax_cycle.relax_cycle(multilevel, 1.0, nu_pre, nu_post, nu_coarsest).run(x)\n",
    "\n",
    "level = multilevel[0]\n",
    "_LOGGER.info(\"RER {:.3f}\".format(norm(level.a.dot(x)) / norm(x)))\n",
    "_LOGGER.info(\"Improving vectors by {} relaxation cycles\".format(num_mini_cycles))\n",
    "x, _ = hm.solve.run.run_iterative_method(level.operator, relax_cycle, x, num_mini_cycles)\n",
    "_LOGGER.info(\"RER {:.3f}\".format(norm(level.a.dot(x)) / norm(x)))\n",
    "x_log.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec93c27-a4c7-4359-8353-253010760004",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_size = 4\n",
    "threshold = 0.1\n",
    "fig, axs = plt.subplots(len(x_log), 3, figsize=(16, 3 * len(x_log)))\n",
    "for row, x in enumerate(x_log):\n",
    "    x_aggregate_t = np.concatenate(\n",
    "        tuple(hm.linalg.get_window(x, offset, aggregate_size)\n",
    "              for offset in range(max((4 * aggregate_size) // x.shape[1], 1))), axis=1).transpose()    \n",
    "#     start, end = 0, aggregate_size\n",
    "#     x_aggregate_t = x[start:end].transpose()\n",
    "    r, s = hrc.create_coarsening(x_aggregate_t, threshold)\n",
    "    r = r.asarray()\n",
    "\n",
    "    # Relaxed vectors.\n",
    "    ax = axs[row, 0]\n",
    "    for i in range(3):\n",
    "        ax.plot(x[:, i]);\n",
    "    ax.grid(True)\n",
    "    ax.set_title(r\"Test Vectors at Step {}\".format(row))\n",
    "\n",
    "    ax = axs[row, 1]\n",
    "    # R should be real-valued, but cast just in case.\n",
    "    for i, ri in enumerate(np.real(r)):\n",
    "        ax.plot(ri)\n",
    "    ax.set_title(r\"PC Agg Size {} $n_c$ {}\".format(r.shape[1], r.shape[0]))\n",
    "    ax.set_ylabel(r\"$R$ rows\")\n",
    "    ax.grid(True);\n",
    "\n",
    "    # Singular values, normalized to sigma_max = 1.\n",
    "    ax = axs[row, 2]\n",
    "    ax.plot(s / s[0], \"rx\")\n",
    "    ax.set_title(\"Singular Values\")\n",
    "    ax.set_xlabel(r\"$k$\")\n",
    "    ax.set_ylabel(r\"$\\sigma_k$\")\n",
    "    ax.grid(True);\n",
    "    \n",
    "    print(\"Step {:2d}\".format(row), \"s\", s / s[0], \"Energy error\", (1 - np.cumsum(s ** 2) / sum(s ** 2)) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b64a6-f6ec-4334-8ba1-eeefb849a5cc",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea737773-bc8d-469e-bbeb-63f4d681c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = multilevel[0]\n",
    "coarse_level = multilevel[1]\n",
    "xc = coarse_level.coarsen(x)\n",
    "\n",
    "hm.setup.alignment.calculate_local_repetitive_rotation_angle(4 * aggregate_size, num_components, xc);\n",
    "\n",
    "# Local alignment.\n",
    "_LOGGER.info(\"Local alignment\")\n",
    "phi = hm.setup.alignment.calculate_local_rotation_angles(level.size, aggregate_size, num_components, xc)\n",
    "\n",
    "# Global alignment.\n",
    "_LOGGER.info(\"Global alignment\")\n",
    "f, tmin = hm.setup.alignment.optimal_rotation_angle(xc)\n",
    "\n",
    "# Plot f(theta).\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "hm.setup.alignment.plot_min_functions(n, aggregate_size, num_components, xc, ax)\n",
    "ax.set_title(\"Local Alignment\");\n",
    "\n",
    "ax = axs[1]\n",
    "t = np.linspace(0, 2 * np.pi, 100)\n",
    "ax.plot(t / np.pi, np.array([f(theta) for theta in t]))\n",
    "ax.grid(True);\n",
    "ax.set_xlabel(r\"$\\theta / \\pi$\")\n",
    "ax.set_ylabel(r\"$f(\\theta)$\");\n",
    "ax.set_title(\"Global Alignment\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca8161-b8a0-45f0-9499-9e4ed2931ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(multilevel[1].a.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2d27c-19d3-4f1b-8b73-a89747129c0d",
   "metadata": {},
   "source": [
    "<!-- ### Solving $A x = b$ (Periodic Fixed-Size Domain Problem)\n",
    "That is, solving on a periodic fixed d\n",
    "omain. $b$ is a random periodic vector. We start from random $x$. Solving exactly on the coarsest level works fine despite the indefiniteness since the matrix is not (even nearly) singular. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb82b6-fbb6-427e-9dd7-4ce7686a4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level = multilevel.finest_level\n",
    "# # Test two-level cycle convergence for A*x=0 and  A*x=b with random b.\n",
    "# for title, b in ((\"0\", np.zeros((a0.shape[0], ))), (\"b\", np.random.random((a0.shape[0], )))):\n",
    "#     logger.info(\"Ax={}\".format(title))\n",
    "#     two_level_cycle = lambda y: hm.solve.solve_cycle.solve_cycle(multilevel, 1.0, 2, 1, nu_coarsest=-1, debug=False, rhs=b).run(y)\n",
    "#     residual = lambda x: b - multilevel[0].operator(x)\n",
    "#     x, conv_factor = hm.solve.run.run_iterative_method(residual, two_level_cycle, np.random.random((a0.shape[0], )), 20, print_frequency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3aae95-12b9-4dec-ab26-2e7991ad9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Asymptotic vector.\n",
    "# e = x - multilevel[1].p.dot(multilevel[1].r.dot(x))\n",
    "# plt.plot(x);\n",
    "# plt.plot(e);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a121dfe-596b-444c-a301-d871eed3c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # L2 interpolation error\n",
    "# logger.info(\"|x-P*R*x|     {:.2e}\".format(hm.linalg.scaled_norm(e)))\n",
    "# logger.info(\"|x|           {:.2e}\".format(hm.linalg.scaled_norm(x)))\n",
    "\n",
    "# # Residual norm interpolation error\n",
    "# logger.info(\"|A*(x-P*R*x)| {:.2e}\".format(hm.linalg.scaled_norm(multilevel[0].a.dot(e))))\n",
    "# logger.info(\"|Ax|          {:.2e}\".format(hm.linalg.scaled_norm(multilevel[0].a.dot(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d4935-a1ef-44a2-843c-a24365619e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nu_values = np.arange(1, 7, dtype=int)\n",
    "# r = multilevel[1].r\n",
    "# two_level_cycle = lambda y: hm.solve.solve_cycle.solve_cycle(multilevel, 1.0, 1, 0, nu_coarsest=-1, debug=False, rhs=b).run(y)\n",
    "# residual = lambda x: b - multilevel[0].operator(x)\n",
    "# b = np.random.random((a0.shape[0], ))\n",
    "# mock_conv_factor = np.array([\n",
    "#     hm.setup.auto_setup.mock_cycle_conv_factor(multilevel.finest_level, r, nu) \n",
    "#     for nu in nu_values])\n",
    "# two_level_cycle = np.array([\n",
    "#     hm.solve.run.run_iterative_method(\n",
    "#         residual, \n",
    "#         lambda x: hm.solve.solve_cycle.solve_cycle(multilevel, 1.0, nu, 0, nu_coarsest=-1, rhs=b).run(x), \n",
    "#         np.random.random((multilevel.finest_level.size, )), 20)[1]\n",
    "#     for nu in nu_values])\n",
    "\n",
    "# for nu, mock, two_level in zip(nu_values, mock_conv_factor, two_level_cycle):\n",
    "#     print(\"V({}, {}) conv factor {:.3f} mock cycle {:.3f}\".format(nu, 0, two_level, mock))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a56bac-0c33-40de-8814-34bfb1f14f3a",
   "metadata": {},
   "source": [
    "<!-- For some reason, 1 relaxation per cycle is more efficient than $2-4$ per cycle! Note that we are solving $Ax=b$, not $Ax=0$. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26119034-2ab5-4be3-ac9d-ed9fa5156dba",
   "metadata": {},
   "source": [
    "## Spectra of Different Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b01225-71a7-4934-a749-7b94f0b7537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate eigenpairs at all levels.\n",
    "# vl = []\n",
    "# laml = []\n",
    "# for l, level in enumerate(multilevel):\n",
    "#     a = level.a\n",
    "#     lam, v = eig(a.todense())\n",
    "#     lam = np.real(lam)\n",
    "#     ind = np.argsort(np.abs(lam))\n",
    "#     lam = lam[ind]\n",
    "#     v = v[:, ind]\n",
    "#     vl.append(v)\n",
    "#     laml.append(lam)\n",
    "#     print(l, \"lam\", lam[:13])\n",
    "    \n",
    "# # Interpolate eigenvectors at all levels to the finest level.\n",
    "# num_levels = len(multilevel)\n",
    "# vl_finest = []\n",
    "# for l in range(num_levels):\n",
    "#     v = vl[l]\n",
    "#     for k in range(l, 0, -1):\n",
    "#         v = multilevel[k].p.dot(v)\n",
    "#     vl_finest.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f493524-7901-409a-8940-d8ea1697bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_ev = 8\n",
    "# num_levels = len(multilevel)\n",
    "# fig, axs = plt.subplots(num_ev, num_levels, figsize=(16, 16))\n",
    "\n",
    "# for col, ax in enumerate(axs[0]):\n",
    "#     ax.set_title(\"Level {}\".format(col))\n",
    "\n",
    "# for i in range(num_ev):\n",
    "#     for l in range(num_levels):\n",
    "#         ax = axs[i, l]\n",
    "#         ax.plot(np.real(vl[l][:, i]), label=\"$\\lambda_i = {:.3f}$\".format(laml[l][i]))\n",
    "#         ax.legend(loc=\"upper right\")\n",
    "#         ax.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77e26a-515e-4231-b31c-54e8658360ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
