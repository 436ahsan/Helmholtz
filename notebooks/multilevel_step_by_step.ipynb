{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "failing-perfume",
   "metadata": {},
   "source": [
    "# Helmholtz 1D: Building The Multilevel Hierarchy, Step-by-Step\n",
    "* Discretization: 5-point (4th order).\n",
    "* Fixed-domain problem; non-repetitive, so we generate TVs over entire domain.\n",
    "* Fix aggregate size to $4$ points. Consider a certain aggregate in the domain (say, the first one).\n",
    "* Observe beahviour vs. $\\nu$:\n",
    "  * Create relaxed TVs with $\\nu$ Kaczmarz relaxation sweeps.\n",
    "  * Create the coarsening operator $R$ using SVD. Observe singular value decay rate.\n",
    "  * Observe two-level mini-cycle convergence factor before slowing down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f9a6bc-e552-4822-8d23-4bd05d2975f8",
   "metadata": {},
   "source": [
    "## Shrinkage Factor\n",
    "Given an iterative method, we can calculate whether it's a good smoothing candidate using the **shrinkage factor** $\\mu$, even before measuring its mock cycle rate (which measures the combination of the smoother andcoarsening operator $R$).\n",
    "\n",
    "* Start from $5$ different random starts $x_0 = rand[-1,1]$, for each  apply the method for $A x = 0$ to obtain iterates $x_1, x_2, \\dots$.\n",
    "* For each iterate, calculate residual norm $r_i := \\|A x_i\\|_2$ and reduction per sweep, $\\mu_i := (r_i / r_0)^{\\frac{1}{i}}$, $i = 1, 2, \\dots$.\n",
    "* Average $\\mu_i$ over the $5$ starts.\n",
    "* Terminate the method at $j = i + 3$, where $i = argmin_i \\mu_i$ and set $\\mu \\leftarrow \\mu_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatal-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helmholtz as hm\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import sklearn.metrics.pairwise\n",
    "import sys\n",
    "from numpy.ma.testutils import assert_array_almost_equal\n",
    "from scipy.linalg import eig, norm, svd\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy import optimize\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(linewidth=500, precision=3, suppress=True, threshold=100000)\n",
    "for handler in logging.root.handlers[:]: logging.root.removeHandler(handler)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format=\"%(levelname)-8s %(message)s\",\n",
    "                    datefmt=\"%a, %d %b %Y %H:%M:%S\")\n",
    "\n",
    "logger = logging.getLogger(\"main\")\n",
    "_LOGGER = logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9dfed3-c264-489a-9275-5abef457cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coarsening(level, aggregate_size: int = 4):\n",
    "    \"\"\"Checks coarsening based on relaxed TVs, for different number of relaxation sweeps.\n",
    "    If aggregate_size is not None, forces that aggregate size for the entire domain.\"\"\"\n",
    "    num_sweeps_values = 5 * 2 ** np.arange(8)\n",
    "\n",
    "    fig, axs = plt.subplots(len(num_sweeps_values), 3, figsize=(16, 3 * len(num_sweeps_values)))\n",
    "    for row, num_sweeps in enumerate(num_sweeps_values):\n",
    "        # Create relaxed TVs.\n",
    "        x = hm.solve.run.run_iterative_method(\n",
    "            level.operator, lambda x: level.relax(x, b), x_random, num_sweeps=num_sweeps)[0]\n",
    "\n",
    "        start, end = 0, aggregate_size\n",
    "        x_aggregate_t = x[start:end].transpose()\n",
    "        r, s = hm.setup.coarsening.create_coarsening(x_aggregate_t, threshold)\n",
    "        r = r.asarray()\n",
    "\n",
    "        # Relaxed vectors.\n",
    "        ax = axs[row, 0]\n",
    "        for i in range(3):\n",
    "            ax.plot(x[:, i]);\n",
    "        ax.grid(True)\n",
    "        ax.set_title(r\"Test Vectors, $\\nu={}$ sweeps\".format(num_sweeps))\n",
    "\n",
    "        ax = axs[row, 1]\n",
    "        # R should be real-valued, but cast just in case.\n",
    "        for i, ri in enumerate(np.real(r)):\n",
    "            ax.plot(ri)\n",
    "        ax.set_title(r\"Agg Size {} $n_c$ {}\".format(r.shape[1], r.shape[0]))\n",
    "        ax.set_ylabel(r\"$R$ rows\")\n",
    "        ax.grid(True);\n",
    "\n",
    "        # Singular values, normalized to sigma_max = 1.\n",
    "        ax = axs[row, 2]\n",
    "        ax.plot(s / s[0], \"rx\")\n",
    "        ax.set_title(\"Singular Values\")\n",
    "        ax.set_xlabel(r\"$k$\")\n",
    "        ax.set_ylabel(r\"$\\sigma_k$\")\n",
    "        ax.grid(True);\n",
    "\n",
    "        print(\"nu\", \"{:2d}\".format(num_sweeps), \"s\", s / s[0], \"Energy error\", (1 - np.cumsum(s ** 2) / sum(s ** 2)) ** 0.5)\n",
    "\n",
    "        # Generate coarse variables (R) on the non-repetitive domain.\n",
    "        r, aggregates, nc, energy_error = hm.setup.coarsening.create_coarsening_domain(x, threshold=threshold,\n",
    "                                                                                           fixed_aggregate_size=aggregate_size)\n",
    "        _LOGGER.info(\"Agg {}\".format(np.array([len(aggregate) for aggregate in aggregates])))\n",
    "        _LOGGER.info(\"nc  {}\".format(nc))\n",
    "        _LOGGER.info(\"Energy error mean {:.4f} max {:.4f}\".format(np.mean(energy_error), np.max(energy_error)))\n",
    "        mock_conv_factor = np.array(\n",
    "            [hm.setup.auto_setup.mock_cycle_conv_factor(level, r, nu) for nu in np.arange(1, 16, dtype=int)])\n",
    "        _LOGGER.info(\"Mock cycle conv factor {}\".format(np.array2string(mock_conv_factor, precision=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca363760-f09e-4ea3-9c3e-81aadf98c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed seed for reproducible results.\n",
    "np.random.seed(0)\n",
    "\n",
    "# Domain size.\n",
    "n = 96\n",
    "# Scaled wave number.\n",
    "kh = 0.5\n",
    "\n",
    "# Number of test vectors.\n",
    "num_examples = 20\n",
    "threshold = 0.1\n",
    "\n",
    "# Boottstrapping parameters.\n",
    "threshold = 0.1\n",
    "interpolation_method = \"ls\"\n",
    "num_test_examples = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e51279-8734-442c-88db-462f5b1edaab",
   "metadata": {},
   "source": [
    "## Level 0->1 Coarsening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a77b33-41f8-4b8e-b930-b1111f783374",
   "metadata": {},
   "source": [
    "### Relaxation Shrinkage Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b90d7d-a93c-4c7e-bacd-19b5f15e878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kh 0\n",
      "INFO     Iter     |r|                         |x|         RER\n",
      "INFO     0     1.442e+00                    4.470e-01    3.223\n",
      "INFO     1     7.733e-01 (0.537) [0.537]    3.302e-01    2.352 (0.728)\n",
      "INFO     2     4.380e-01 (0.567) [0.552]    2.782e-01    1.591 (0.675)\n",
      "INFO     3     2.670e-01 (0.611) [0.571]    2.529e-01    1.071 (0.673)\n",
      "INFO     4     1.782e-01 (0.668) [0.594]    2.386e-01    0.759 (0.709)\n",
      "INFO     5     1.313e-01 (0.737) [0.620]    2.293e-01    0.581 (0.767)\n",
      "INFO     6     1.053e-01 (0.802) [0.648]    2.225e-01    0.480 (0.827)\n",
      "INFO     7     8.955e-02 (0.850) [0.673]    2.172e-01    0.417 (0.871)\n",
      "INFO     8     7.901e-02 (0.881) [0.696]    2.128e-01    0.375 (0.900)\n",
      "INFO     9     7.133e-02 (0.902) [0.717]    2.090e-01    0.344 (0.918)\n",
      "INFO     10    6.539e-02 (0.915) [0.735]    2.057e-01    0.320 (0.930)\n",
      "INFO     11    6.063e-02 (0.925) [0.750]    2.028e-01    0.301 (0.939)\n",
      "INFO     12    5.665e-02 (0.932) [0.764]    2.002e-01    0.285 (0.945)\n",
      "INFO     13    5.330e-02 (0.939) [0.777]    1.978e-01    0.271 (0.950)\n",
      "INFO     14    5.043e-02 (0.944) [0.788]    1.956e-01    0.259 (0.955)\n",
      "INFO     15    4.792e-02 (0.948) [0.798]    1.936e-01    0.249 (0.958)\n",
      "INFO     16    4.573e-02 (0.952) [0.806]    1.917e-01    0.239 (0.962)\n",
      "INFO     17    4.378e-02 (0.956) [0.815]    1.899e-01    0.231 (0.965)\n",
      "INFO     18    4.203e-02 (0.959) [0.822]    1.883e-01    0.224 (0.967)\n",
      "INFO     19    4.046e-02 (0.961) [0.829]    1.867e-01    0.217 (0.969)\n",
      "INFO     20    3.903e-02 (0.964) [0.835]    1.853e-01    0.211 (0.971)\n",
      "Kac        RER at point of diminishing returns 0.13 num_sweeps  5 work  1 residual-per-sweep 0.53\n",
      "INFO     Iter     |r|                         |x|         RER\n",
      "INFO     0     1.455e+00                    4.467e-01    3.263\n",
      "INFO     1     5.724e-01 (0.394) [0.394]    2.626e-01    2.189 (0.670)\n",
      "INFO     2     2.361e-01 (0.412) [0.403]    1.963e-01    1.213 (0.553)\n",
      "INFO     3     1.039e-01 (0.440) [0.415]    1.698e-01    0.619 (0.510)\n",
      "INFO     4     5.077e-02 (0.488) [0.432]    1.561e-01    0.330 (0.532)\n",
      "INFO     5     2.825e-02 (0.557) [0.455]    1.472e-01    0.195 (0.591)\n",
      "INFO     6     1.832e-02 (0.649) [0.483]    1.406e-01    0.132 (0.680)\n",
      "INFO     7     1.340e-02 (0.732) [0.512]    1.353e-01    0.101 (0.761)\n",
      "INFO     8     1.062e-02 (0.792) [0.541]    1.308e-01    0.082 (0.819)\n",
      "INFO     9     8.859e-03 (0.833) [0.568]    1.270e-01    0.071 (0.859)\n",
      "INFO     10    7.629e-03 (0.860) [0.592]    1.236e-01    0.063 (0.884)\n",
      "INFO     11    6.713e-03 (0.879) [0.614]    1.206e-01    0.056 (0.901)\n",
      "INFO     12    5.999e-03 (0.893) [0.633]    1.179e-01    0.052 (0.914)\n",
      "INFO     13    5.422e-03 (0.903) [0.651]    1.155e-01    0.048 (0.923)\n",
      "INFO     14    4.944e-03 (0.911) [0.667]    1.132e-01    0.044 (0.929)\n",
      "INFO     15    4.541e-03 (0.918) [0.681]    1.112e-01    0.041 (0.935)\n",
      "INFO     16    4.193e-03 (0.923) [0.694]    1.093e-01    0.039 (0.939)\n",
      "INFO     17    3.891e-03 (0.928) [0.706]    1.076e-01    0.036 (0.943)\n",
      "INFO     18    3.626e-03 (0.931) [0.717]    1.059e-01    0.034 (0.946)\n",
      "INFO     19    3.390e-03 (0.935) [0.727]    1.044e-01    0.033 (0.948)\n",
      "INFO     20    3.180e-03 (0.937) [0.736]    1.030e-01    0.031 (0.950)\n",
      "GS         RER at point of diminishing returns 0.03 num_sweeps  5 work  1 residual-per-sweep 0.39\n",
      "kh 0.5\n",
      "INFO     Iter     |r|                         |x|         RER\n",
      "INFO     0     1.321e+00                    4.471e-01    2.956\n",
      "INFO     1     7.237e-01 (0.548) [0.548]    3.384e-01    2.141 (0.724)\n",
      "INFO     2     4.258e-01 (0.588) [0.568]    2.891e-01    1.475 (0.689)\n",
      "INFO     3     2.670e-01 (0.627) [0.587]    2.638e-01    1.014 (0.687)\n",
      "INFO     4     1.827e-01 (0.684) [0.610]    2.493e-01    0.735 (0.724)\n",
      "INFO     5     1.346e-01 (0.737) [0.633]    2.400e-01    0.562 (0.765)\n",
      "INFO     6     1.064e-01 (0.791) [0.657]    2.334e-01    0.457 (0.814)\n",
      "INFO     7     8.880e-02 (0.835) [0.680]    2.283e-01    0.390 (0.854)\n",
      "INFO     8     7.731e-02 (0.871) [0.701]    2.241e-01    0.346 (0.887)\n",
      "INFO     9     6.942e-02 (0.898) [0.721]    2.205e-01    0.315 (0.912)\n",
      "INFO     10    6.370e-02 (0.918) [0.738]    2.174e-01    0.294 (0.931)\n",
      "INFO     11    5.937e-02 (0.932) [0.754]    2.146e-01    0.277 (0.944)\n",
      "INFO     12    5.593e-02 (0.942) [0.768]    2.120e-01    0.265 (0.954)\n",
      "INFO     13    5.307e-02 (0.949) [0.781]    2.096e-01    0.254 (0.960)\n",
      "INFO     14    5.064e-02 (0.954) [0.792]    2.074e-01    0.245 (0.964)\n",
      "INFO     15    4.853e-02 (0.958) [0.802]    2.053e-01    0.237 (0.968)\n",
      "INFO     16    4.669e-02 (0.962) [0.811]    2.033e-01    0.230 (0.971)\n",
      "INFO     17    4.506e-02 (0.965) [0.820]    2.014e-01    0.224 (0.974)\n",
      "INFO     18    4.360e-02 (0.968) [0.827]    1.997e-01    0.219 (0.976)\n",
      "INFO     19    4.227e-02 (0.970) [0.834]    1.980e-01    0.214 (0.978)\n",
      "INFO     20    4.106e-02 (0.971) [0.841]    1.963e-01    0.210 (0.979)\n",
      "Kac        RER at point of diminishing returns 0.11 num_sweeps  6 work  1 residual-per-sweep 0.57\n",
      "INFO     Iter     |r|                         |x|         RER\n",
      "INFO     0     1.378e+00                    4.468e-01    3.079\n",
      "INFO     1     5.731e-01 (0.417) [0.417]    3.056e-01    1.880 (0.612)\n",
      "INFO     2     2.519e-01 (0.440) [0.428]    2.784e-01    0.914 (0.486)\n",
      "INFO     3     1.268e-01 (0.504) [0.452]    2.976e-01    0.433 (0.473)\n",
      "INFO     4     8.796e-02 (0.690) [0.503]    3.372e-01    0.263 (0.610)\n",
      "INFO     5     8.661e-02 (0.974) [0.574]    3.921e-01    0.220 (0.839)\n",
      "INFO     6     9.963e-02 (1.141) [0.645]    4.623e-01    0.214 (0.971)\n",
      "GS         RER at point of diminishing returns 0.13 num_sweeps  3 work  1 residual-per-sweep 0.35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kh_values = [0, 0.5]\n",
    "fig, axs = plt.subplots(1, len(kh_values), figsize=(12, 4))\n",
    "\n",
    "kaczmarz = lambda a: hm.solve.relax.KaczmarzRelaxer(a, scipy.sparse.eye(a.shape[0]))\n",
    "gs = lambda a: hm.solve.relax.GsRelaxer(a)\n",
    "work = 1\n",
    "\n",
    "# Kaczmarz.\n",
    "for kh_value, ax in zip(kh_values, axs):\n",
    "    print(\"kh\", kh_value)\n",
    "    a_kh = hm.linalg.helmholtz_1d_5_point_operator(kh_value, n).tocsr()\n",
    "    operator = lambda x: a_kh.dot(x)\n",
    "\n",
    "    for title, relax, color in zip((\"Kac\", \"GS\"), (kaczmarz, gs), (\"blue\", \"red\")):\n",
    "        method = relax(a_kh)\n",
    "        factor, num_sweeps, residual, conv, rer, relax_conv_factor = hm.solve.smoothing.shrinkage_factor(\n",
    "            operator, lambda x, b: method.step(x, b), (a_kh.shape[0], ), \n",
    "            print_frequency=1, max_sweeps=20, slow_conv_factor=1.1)\n",
    "        hm.solve.smoothing.plot_diminishing_returns_point(factor, num_sweeps, conv, ax, title=title, color=color)\n",
    "        print(\"{:<10s} RER at point of diminishing returns {:.2f} num_sweeps {:>2d} work {:>2d} residual-per-sweep {:.2f}\".format(\n",
    "            title, np.mean(residual[num_sweeps]), num_sweeps, work, np.mean(residual[num_sweeps] / rer[0]) ** (1/(num_sweeps * work))))\n",
    "    \n",
    "    ax.set_title(r\"$kh = {:.2f}$\".format(kh_value))\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d8cb5-0318-48e8-aa7d-7634e3ae6407",
   "metadata": {
    "tags": []
   },
   "source": [
    "The point of diminishing returns in each scatterplot is circled.\n",
    "\n",
    "This estimate seems to give a reasonable estimate for both $kh$ values and both relaxation schemes (albeit not a quantitative smoothing factor, which can only be defined based on a coarsening), showing that GS is a better smoother for both $kh = 0, 0.5$, but slightly diverges for $kh = 0.5$. The RER at the point of diminishing returns is much smaller.\n",
    "\n",
    "Averaging over multiple random starts helps reduce noise, as well as assuming a constant reduction per sweep in the initial sweeps (as opposed to a linear model, say). We are only interested in a rough estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8ea80-45ed-47b0-aa8e-85fcdc5526e6",
   "metadata": {},
   "source": [
    "### Coarsening Quality\n",
    "We measure the gap between the second and third singular values as a function of the number of TV relaxation sweeps $\\nu$. We force the aggregate size to be $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e221b74-3315-4384-ae18-7f161bd036b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hm.linalg.helmholtz_1d_5_point_operator(kh, n).tocsr()\n",
    "level = hm.setup.hierarchy.create_finest_level(a)\n",
    "x_random = hm.solve.run.random_test_matrix((a.shape[0],), num_examples=num_examples)\n",
    "b = np.zeros_like(x_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773af8c-0e99-4b8c-ac85-2aa9cb423704",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_coarsening(level, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd45c0-c069-47ac-8488-30d706df2b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_coarsening(level, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630cb7c-8303-464d-9ef4-95063520d214",
   "metadata": {},
   "source": [
    "The gap $\\sigma_2 - \\sigma_3$ increases with $\\nu$, showing that an aggregate size of $4$ is fine (we can obtain an energy error as small as we want given a large enough $\\nu$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065cab5-5772-4cb6-9a38-e623ecfce1e0",
   "metadata": {},
   "source": [
    "### Two-level Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5163b8-56d3-4349-8f04-7fba7292a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_levels = 2\n",
    "num_bootstrap_steps = 1\n",
    "num_sweeps = 10\n",
    "fixed_aggregate_size = None # 6\n",
    "\n",
    "x_log = []\n",
    "r_log = []\n",
    "\n",
    "# Initialize hierarchy to 1-level and fine-level test functions to random.\n",
    "finest = 0\n",
    "multilevel = hm.hierarchy.multilevel.Multilevel(level)\n",
    "\n",
    "_LOGGER.info(\"Relax at level {} size {}\".format(finest, level.size))\n",
    "b = np.zeros((a.shape[0], num_examples))\n",
    "_, relax_conv_factor = hm.solve.run.run_iterative_method(\n",
    "    level.operator, lambda x: level.relax(x, b), \n",
    "    hm.solve.run.random_test_matrix((a.shape[0],), num_examples=num_examples), num_sweeps=100)\n",
    "_LOGGER.info(\"Relax convergence factor {:.3f}\".format(relax_conv_factor))\n",
    "\n",
    "# TODO(orenlivne): generalize to d-dimensions. This is specific to 1D.\n",
    "x = hm.solve.run.random_test_matrix((a.shape[0],), num_examples=num_examples)\n",
    "# Improve vectors with 1-level relaxation.\n",
    "x_log.append(x)\n",
    "\n",
    "_LOGGER.info(\"Generating TVs with {} sweeps\".format(num_sweeps))\n",
    "x, _ = hm.solve.run.run_iterative_method(\n",
    "    level.operator, lambda x: level.relax(x, b), x, num_sweeps=num_sweeps)\n",
    "_LOGGER.info(\"RER {:.3f}\".format(norm(a.dot(x)) / norm(x)))\n",
    "x_log.append(x)\n",
    "\n",
    "# Bootstrap with an increasingly deeper hierarchy (add one level at a time).\n",
    "num_levels = 2\n",
    "_LOGGER.info(\"bootstrap on grid size {} with {} levels\".format(x.shape[0], max_levels))\n",
    "_LOGGER.info(\"-\" * 80)\n",
    "for i in range(num_bootstrap_steps):\n",
    "    _LOGGER.info(\"Bootstrap step {}/{}\".format(i + 1, num_bootstrap_steps))\n",
    "    # Set relax_conv_factor to a high value so that we never append a bootstrap vector to the TV set.\n",
    "    x, multilevel = hm.setup.auto_setup.bootstap(\n",
    "        x, multilevel, num_levels, 2.0,\n",
    "        num_sweeps=num_sweeps, interpolation_method=interpolation_method, \n",
    "        threshold=threshold, fixed_aggregate_size=fixed_aggregate_size)\n",
    "    x_log.append(x)\n",
    "    r_log.append(multilevel.level[1].r)\n",
    "    _LOGGER.info(\"RER {:.6f}\".format(norm(a.dot(x)) / norm(x)))\n",
    "    _LOGGER.info(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a8fb4-4b1b-4b4e-9fc8-6f7edad2c751",
   "metadata": {},
   "source": [
    "### Relaxation Cycle Shrinkage\n",
    "We compare relaxation cycle with $\\nu_1=2, \\nu_2=2, \\nu_{coarse}=20$ with the resulting $P$ and $R$ from the bootstrap step, with Kaczmarz relaxation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41236d4e-a5c9-47a6-9ca6-fde1cd7d3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.solve.smoothing.check_relax_cycle_shrinkage(multilevel, nu_coarsest=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a2cbf-c729-42bc-9c35-53d0d5e020c2",
   "metadata": {},
   "source": [
    "Even though per work unit it is about the same (the mini-cycle is $6$ relaxations worth), the two-level relaxation cycle reduces the RER much more than Kaczmarz until the point of diminishing returns.\n",
    "\n",
    "As expected, both methods are asymptotically slow (probably the same rate of convergence)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b4cda-cd2b-46e2-bb8d-fe7f951aded1",
   "metadata": {},
   "source": [
    "### Effect of a Second Bootstrap Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6366c6-95b5-4b22-b685-39e4fab43b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, multilevel = hm.setup.auto_setup.bootstap(\n",
    "    x, multilevel, num_levels, 2.0,\n",
    "    num_sweeps=num_sweeps, interpolation_method=interpolation_method, threshold=threshold)\n",
    "x_log.append(x)\n",
    "r_log.append(multilevel.level[1].r)\n",
    "_LOGGER.info(\"RER {:.3f}\".format(norm(a.dot(x)) / norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a78ec7-b0c1-4c62-9087-a18933889e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.solve.smoothing.check_relax_cycle_shrinkage(multilevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f9d08-df1d-47a4-ab41-f00778e8bf3f",
   "metadata": {},
   "source": [
    "Looks like the final RER obtained with a relaxation cycle after one and two bootstrap cycles is the same, so we didn't make it worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead05348-170e-4f90-bf97-f9e9d1ca3c9e",
   "metadata": {},
   "source": [
    "### Effect of Bootstrap on $R$'s Singular Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a02978-28b1-48e2-80a3-2b760bed3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final R from the most updated TVs.\n",
    "x_fit, x_test = x[:, :-num_test_examples], x[:, -num_test_examples:]\n",
    "\n",
    "# Create the coarsening operator R.\n",
    "r, aggregates, nc, energy_error = hm.setup.coarsening.create_coarsening_domain(x_fit, threshold=threshold)\n",
    "r_log.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d748fa6-3fc7-4dcc-86b6-0df2ed26d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_size = 4\n",
    "fig, axs = plt.subplots(len(x_log), 3, figsize=(16, 3 * len(x_log)))\n",
    "for row, x in enumerate(x_log):\n",
    "    start, end = 0, aggregate_size\n",
    "    x_aggregate_t = x[start:end].transpose()\n",
    "    r, s = hm.setup.coarsening.create_coarsening(x_aggregate_t, threshold)\n",
    "    r = r.asarray()\n",
    "\n",
    "    # Relaxed vectors.\n",
    "    ax = axs[row, 0]\n",
    "    for i in range(3):\n",
    "        ax.plot(x[:, i]);\n",
    "    ax.grid(True)\n",
    "    ax.set_title(r\"Test Vectors at Step {}\".format(row))\n",
    "\n",
    "    ax = axs[row, 1]\n",
    "    # R should be real-valued, but cast just in case.\n",
    "    for i, ri in enumerate(np.real(r)):\n",
    "        ax.plot(ri)\n",
    "    ax.set_title(r\"Agg Size {} $n_c$ {}\".format(r.shape[1], r.shape[0]))\n",
    "    ax.set_ylabel(r\"$R$ rows\")\n",
    "    ax.grid(True);\n",
    "\n",
    "    # Singular values, normalized to sigma_max = 1.\n",
    "    ax = axs[row, 2]\n",
    "    ax.plot(s / s[0], \"rx\")\n",
    "    ax.set_title(\"Singular Values\")\n",
    "    ax.set_xlabel(r\"$k$\")\n",
    "    ax.set_ylabel(r\"$\\sigma_k$\")\n",
    "    ax.grid(True);\n",
    "    \n",
    "    print(\"Step {:2d}\".format(row), \"s\", s / s[0], \"Energy error\", (1 - np.cumsum(s ** 2) / sum(s ** 2)) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13570b46-ff2f-4d57-99c5-85255d84afc0",
   "metadata": {},
   "source": [
    "With bootstrap cycles, the smoother the TVs and the better the singular value separation: $R$ is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d7a65-a370-49bc-b56b-1a2dc8eee675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-level TVs.\n",
    "x_fine = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984b180-0dd4-40e1-90dd-bfbbdedb91b1",
   "metadata": {},
   "source": [
    "## Level 1->2 Coarsening\n",
    "Are the equations at level 1 harder to solve than level 0 because of worse smoothing rates? Do we see a good coarsening ratio for an aggregate of size $4$ here too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9c302-68ef-42b5-b6f0-7918e7ec3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = multilevel.level[1]\n",
    "a = level.a\n",
    "x_random = hm.solve.run.random_test_matrix((a.shape[0],), num_examples=num_examples)\n",
    "b = np.zeros_like(x_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ff870-2b78-4ca0-84c9-7ce1dad737b2",
   "metadata": {},
   "source": [
    "### Relaxation Shrinkage Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650947b7-aa5d-45bf-ae11-d40ddb76bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaczmarz = lambda a: hm.solve.relax.KaczmarzRelaxer(a, scipy.sparse.eye(a.shape[0]))\n",
    "gs = lambda a: hm.solve.relax.GsRelaxer(a)\n",
    "work = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "# Kaczmarz.\n",
    "operator = lambda x: a.dot(x)\n",
    "for title, relax, color in zip((\"Kac\", ), (kaczmarz, ), (\"blue\", )):\n",
    "    method = relax(a)\n",
    "    factor, num_sweeps, rer, conv = hm.solve.smoothing.shrinkage_factor(\n",
    "        operator, lambda x, b: method.step(x, b), (a.shape[0], ), print_frequency=1, max_sweeps=20, slow_conv_factor=2, num_examples=1)\n",
    "    hm.solve.smoothing.plot_diminishing_returns_point(factor, num_sweeps, conv, ax, title=title, color=color)\n",
    "    print(\"{:<10s} RER at point of diminishing returns {:.2f} num_sweeps {:>2d} work {:>2d} RER-per-sweep {:.2f}\".format(\n",
    "        title, np.mean(rer[num_sweeps]), num_sweeps, work, np.mean(rer[num_sweeps] / rer[0]) ** (1/(num_sweeps * work))))\n",
    "\n",
    "ax.set_title(r\"$kh = {:.2f}$\".format(kh_value))\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfa8255-97d9-46ff-b889-fa3efe612dcb",
   "metadata": {},
   "source": [
    "Kaczmarz slows down more quickly here than on level 1. GS diverges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071e7fb-a825-4f61-81e8-8dee06e7a77f",
   "metadata": {},
   "source": [
    "### $R$ for Aggregate Size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e874ef-28c5-460b-9870-290a4bcaff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_coarsening(level, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f97445-a087-4ca1-b56e-b2e24233df00",
   "metadata": {},
   "source": [
    "It looks like it takes a lot more relaxation sweeps to see $2$ components in a size $4$ aggregate here. Mock cycle rates are also worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02629c15-8e96-4e0b-87a4-b907e8eaa6e9",
   "metadata": {},
   "source": [
    "### $R$ for Aggregate Size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c5adb-10cd-4a90-94ed-d911326e63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_coarsening(level, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e96ff-267f-4318-9f38-a52bcc490e5d",
   "metadata": {},
   "source": [
    "One can obtain a good coarsening here too (in terms of coarsening ratio and mock cycle rates), with an aggregate size of $6$ and $3$ coarse variables. Note that this requires less smoothing ($\\nu = 40$) than for an aggregate size of $4$, where we stll $3$ PCs until $\\nu$ is much larger ($320$). Thus, a general criterion would find the larger aggregate size.\n",
    "\n",
    "The mock cycle rates are worse than for level 0, but we can still obtain improvement when more relaxations per cycle are added. Convergence of $0.2$ is obtained for $11$ relaxations per cycle, as opposed to $3$ at level 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22077e9f-91d4-4871-9bce-7d0bc9955cd4",
   "metadata": {},
   "source": [
    "### $R$ with Dynamic Aggregate Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6908da70-7fe7-46bd-b628-9c13459f302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_coarsening(level, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26daff38-b358-48f7-a7cb-505526e0686d",
   "metadata": {},
   "source": [
    "### Two-level Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f65f0-4d75-430c-b718-99be2c73c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30\n",
    "max_levels = 2\n",
    "num_bootstrap_steps = 3\n",
    "num_sweeps = 20\n",
    "\n",
    "x_log = []\n",
    "r_log = []\n",
    "\n",
    "# Initialize hierarchy to 1-level and fine-level test functions to random.\n",
    "finest = 0\n",
    "multilevel = hm.hierarchy.multilevel.Multilevel(level)\n",
    "\n",
    "_LOGGER.info(\"Relax at level {} size {}\".format(finest, level.size))\n",
    "b = np.zeros((a.shape[0], num_examples))\n",
    "_, relax_conv_factor = hm.solve.run.run_iterative_method(\n",
    "    level.operator, lambda x: level.relax(x, b), \n",
    "    hm.solve.run.random_test_matrix((a.shape[0],), num_examples=num_examples), num_sweeps=100)\n",
    "_LOGGER.info(\"Relax convergence factor {:.3f}\".format(relax_conv_factor))\n",
    "\n",
    "# Start from random again. Level 0 doesn't exist here.\n",
    "x = hm.solve.run.random_test_matrix((a.shape[0],), num_examples=num_examples)\n",
    "x_log.append(x)\n",
    "\n",
    "# Improve vectors with 1-level relaxation.\n",
    "_LOGGER.info(\"Generating TVs with {} sweeps\".format(num_sweeps))\n",
    "x, _ = hm.solve.run.run_iterative_method(\n",
    "    level.operator, lambda x: level.relax(x, b), x, num_sweeps=num_sweeps)\n",
    "_LOGGER.info(\"RER {:.3f}\".format(norm(a.dot(x)) / norm(x)))\n",
    "x_log.append(x)\n",
    "\n",
    "# Bootstrap with an increasingly deeper hierarchy (add one level at a time).\n",
    "num_levels = 2\n",
    "_LOGGER.info(\"bootstrap on grid size {} with {} levels\".format(x.shape[0], max_levels))\n",
    "_LOGGER.info(\"-\" * 80)\n",
    "for i in range(num_bootstrap_steps):\n",
    "    _LOGGER.info(\"Bootstrap step {}/{}\".format(i + 1, num_bootstrap_steps))\n",
    "    # Set relax_conv_factor to a high value so that we never append a bootstrap vector to the TV set.\n",
    "    x, multilevel = hm.setup.auto_setup.bootstap(\n",
    "        x, multilevel, num_levels, 2.0,\n",
    "        num_sweeps=num_sweeps, interpolation_method=interpolation_method, threshold=threshold)\n",
    "    x_log.append(x)\n",
    "    r_log.append(multilevel.level[1].r)\n",
    "    _LOGGER.info(\"RER {:.6f}\".format(norm(a.dot(x)) / norm(x)))\n",
    "    _LOGGER.info(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c31202-7643-4a7a-ad9a-1f1961252f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final R from the most updated TVs.\n",
    "x_fit, x_test = x[:, :-num_test_examples], x[:, -num_test_examples:]\n",
    "\n",
    "# Create the coarsening operator R.\n",
    "r, aggregates, nc, energy_error = hm.setup.coarsening.create_coarsening_domain(x_fit, threshold=threshold)\n",
    "r_log.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f9bf6-65f7-4cb1-acea-cc046c4ca54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_size = 4\n",
    "fig, axs = plt.subplots(len(x_log), 3, figsize=(16, 3 * len(x_log)))\n",
    "for row, x in enumerate(x_log):\n",
    "    start, end = 0, aggregate_size\n",
    "    x_aggregate_t = x[start:end].transpose()\n",
    "    r, s = hm.setup.coarsening.create_coarsening(x_aggregate_t, threshold)\n",
    "    r = r.asarray()\n",
    "\n",
    "    # Relaxed vectors.\n",
    "    ax = axs[row, 0]\n",
    "    for i in range(3):\n",
    "        ax.plot(x[:, i]);\n",
    "    ax.grid(True)\n",
    "    ax.set_title(r\"Test Vectors at Step {}\".format(row))\n",
    "\n",
    "    ax = axs[row, 1]\n",
    "    # R should be real-valued, but cast just in case.\n",
    "    for i, ri in enumerate(np.real(r)):\n",
    "        ax.plot(ri)\n",
    "    ax.set_title(r\"Agg Size {} $n_c$ {}\".format(r.shape[1], r.shape[0]))\n",
    "    ax.set_ylabel(r\"$R$ rows\")\n",
    "    ax.grid(True);\n",
    "\n",
    "    # Singular values, normalized to sigma_max = 1.\n",
    "    ax = axs[row, 2]\n",
    "    ax.plot(s / s[0], \"rx\")\n",
    "    ax.set_title(\"Singular Values\")\n",
    "    ax.set_xlabel(r\"$k$\")\n",
    "    ax.set_ylabel(r\"$\\sigma_k$\")\n",
    "    ax.grid(True);\n",
    "    \n",
    "    print(\"Step {:2d}\".format(row), \"s\", s / s[0], \"Energy error\", (1 - np.cumsum(s ** 2) / sum(s ** 2)) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e2196-3794-4068-a67d-4f5b1a5ccfdc",
   "metadata": {},
   "source": [
    "Here we also observe that the singular value gap increases with bootsrap cycles, but no longer monotonically (it is noisy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa8096-0bc7-4324-96c2-e08d372bdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.solve.smoothing.check_relax_cycle_shrinkage(multilevel, max_sweeps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97b13ee-75a4-4a0e-97e0-a0129a7358b1",
   "metadata": {},
   "source": [
    "## Questions\n",
    "* Why aren't level 1 TVs getting smoother with bootstrap cycles? Their RER oscillates wildly between cycles even though the interpolation error is good (see cycle 2->3).\n",
    "* Need a lot more examples (30 instead of 20) on level 1 because apparently there are up to 12 interpolation points in the stencil (if a large enough aggregate is chosen)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
